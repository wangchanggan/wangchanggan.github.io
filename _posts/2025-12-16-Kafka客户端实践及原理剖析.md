---
layout:     post
title:      Kafka客户端实践及原理剖析
date:       2025-12-16
catalog: true
tags:
    - 消息队列
---

# 生产者消息分区机制原理
## 分区
分区的作用就是提供负载均衡的能力，实现系统的高伸缩性（Scalability）。不同的分区能够被放置到不同节点的机器上，而数据的读写操作也都是针对分区这个粒度而进行的，每个节点的机器都能独立地执行各自分区的读写请求处理。并且，还可以通过添加新的节点机器来增加整体系统的吞吐量。

### 分区策略
所谓分区策略是决定生产者将消息发送到哪个分区的算法。Kafka 提供了默认的分区策略，同时它也支持自定义分区策略。

#### 轮询策略
轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是最常用的分区策略之一。

#### 按消息键保序策略
Kafka 允许为每条消息定义消息键，简称为 Key。这个 Key 是一个有着明确业务含义的字符串，比如客户代码、部门编号或是业务 ID 等；也可以用来表征消息元数据。特别是在 Kafka 不支持时间戳的年代，在一些场景中，工程师们都是直接将消息创建时间封装进 Key 里面的。一旦消息被定义了 Key，就可以保证同一个 Key 的所有消息都进入到相同的分区里面，由于每个分区下的消息处理都是有顺序的，故被称为按消息键保序策略。



# 生产者压缩算法
## 怎么压缩
Kafka 的消息层次都分为两层：消息集合（message set）以及消息（message）。一个消息集合中包含若干条日志项（record item），而日志项才是真正封装消息的地方。Kafka 底层的消息日志由一系列消息集合日志项组成。Kafka 通常不会直接操作具体的一条条消息，它总是在消息集合这个层面上进行写入操作。

1. 把消息的公共部分抽取出来放到外层消息集合里面，不用每条消息都保存这些信息。
2. 对整个消息集合进行压缩。

## 何时压缩
在 Kafka 中，压缩可能发生在两个地方：生产者端和 Broker 端。

生产者程序中配置 compression.type 参数即表示启用指定类型的压缩算法。

大部分情况下 Broker 从 Producer 端接收到消息后仅仅是原封不动地保存而不会对其进行任何修改，但有两种例外情况就可能让 Broker 重新压缩消息。

1. Broker 端指定了和 Producer 端不同的压缩算法。
2. Broker 端发生了消息格式转换。所谓的消息格式转换主要是为了兼容老版本的消费者程序。除了压缩之外，还丧失了引以为豪的 Zero Copy 特性。

## 何时解压缩

解压缩发生在消费者程序中，Producer 发送压缩消息到 Broker 后，Broker 照单全收并原样保存起来。当 Consumer 程序请求这部分消息时，Broker 依然原样发送出去，当消息到达 Consumer 端后，由 Consumer 自行解压缩还原成之前的消息。

Kafka 会将启用了哪种压缩算法封装进消息集合中，当 Consumer 读取到消息集合时，它自然就知道了这些消息使用的是哪种压缩算法。

Producer 端压缩、Broker 端保持、Consumer 端解压缩。

除了在 Consumer 端解压缩，Broker 端也会进行解压缩。注：这和前面提到消息格式转换时发生的解压缩是不同的场景。每个压缩过的消息集合在 Broker 端写入时都要发生解压缩操作，目的就是为了对消息执行各种验证。这种解压缩对 Broker 端性能是有一定影响的，特别是对 CPU 的使用率而言。

## 各种压缩算法对比
两个重要的指标：
1. 压缩比
2. 压缩 / 解压缩吞吐量

![](/img/in-post/MQ/Kafka/comparison-of-compression-algorithms.png)

* 在吞吐量方面：LZ4 > Snappy > zstd 和 GZIP；
* 在压缩比方面，zstd > LZ4 > GZIP > Snappy。
* 物理资源，使用 Snappy 算法占用的网络带宽最多，zstd 最少，提供超高的压缩比；
* CPU 使用率，各个算法表现得差不多，只是在压缩时 Snappy 算法使用的 CPU 较多一些，而在解压缩时 GZIP 算法则可能使用更多的 CPU。

## 最佳实践
* 启用压缩的一个条件就是 Producer 程序运行机器上的 CPU 资源要很充足。
* 如果带宽资源有限，建议开启压缩。如果客户端机器 CPU 资源有很多富余，强烈建议开启 zstd 压缩。
* 对不可抗拒的解压缩无能为力，但至少能规避掉那些意料之外的解压缩。有条件的话尽量保证不要出现消息格式转换的情况。



# 无消息丢失配置
Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证。

* 当 Kafka 的若干个 Broker 成功地接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。此时，这条消息在 Kafka 看来就正式变为“已提交”消息了。
* 假如消息保存在 N 个 Kafka Broker 上，那么这个前提条件就是这 N 个 Broker 中至少有 1 个存活。只要这个条件成立，Kafka 就能保证你的这条消息永远不会丢失。

## “消息丢失”案例
### 生产者程序丢失数据
Producer 永远要使用带有回调通知的发送 API，不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。不要小瞧这里的 callback（回调），它能准确地告诉消息是否真的提交成功了。一旦出现消息提交失败的情况，就可以有针对性地进行处理。

### 消费者程序丢失数据
* 维持先消费消息（阅读），再更新位移（书签）的顺序。
* 如果是多线程异步处理消费消息，Consumer 程序不要开启自动提交位移，而是要应用程序手动提交位移。

## 最佳实践
1. 不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。一定要使用带有回调通知的 send 方法。
2. 设置 acks = all。acks 是 Producer 的一个参数，代表了对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。
3. 设置 retries 为一个较大的值。这里的 retries 同样是 Producer 的参数，对应前面提到的 Producer 自动重试。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了retries > 0 的 Producer 能够自动重试消息发送，避免消息丢失。
4. 设置 unclean.leader.election.enable = false。这是 Broker 端的参数，它控制的是哪些 Broker 有资格竞选分区的 Leader。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false，即不允许这种情况的发生。
5. 设置 replication.factor >= 3。这也是 Broker 端的参数。最好将消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余。
6. 设置 min.insync.replicas > 1。这依然是 Broker 端参数，控制的是消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。
7. 确保 replication.factor > min.insync.replicas。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成 replication.factor = min.insync.replicas + 1。
8. 确保消息消费完成再提交。Consumer 端有个参数 enable.auto.commit，最好把它设置成 false，并采用手动提交位移的方式。这对于单 Consumer 多线程处理的场景而言是至关重要的。



# Kafka 拦截器
其基本思想就是允许应用程序在不修改逻辑的情况下，动态地实现一组可插拔的事件处理逻辑链。

分为生产者拦截器和消费者拦截器。生产者拦截器允许在发送消息前以及消息提交成功后植入拦截器逻辑；而消费者拦截器支持在消费消息前以及提交位移后编写特定逻辑。这两种拦截器都支持链的方式，即可以将一组拦截器串连成一个大的拦截器，Kafka 会按照添加顺序依次执行拦截器逻辑。

当前 Kafka 拦截器的设置方法是通过参数配置完成的。生产者和消费者两端有一个相同的参数，名字叫 interceptor.classes，它指定的是一组类的列表，每个类就是特定逻辑的拦截器实现类。

编写的所有 Producer 端拦截器实现类都要继承 org.apache.kafka.clients.producer.ProducerInterceptor 接口。该接口是 Kafka 提供的，里面有两个核心的方法。

1. onSend：该方法会在消息发送之前被调用。如果想在发送之前对消息“美美容”，这个方法是唯一的机会。
2. onAcknowledgement：该方法会在消息成功提交或发送失败之后被调用。onAcknowledgement 的调用要早于 callback 的调用。值得注意的是，这个方法和 onSend 不是在同一个线程中被调用的，因此如果在这两个方法中调用了某个共享可变对象，一定要保证线程安全。这个方法处在 Producer 发送的主路径中，所以最好别放一些太重的逻辑，否则 Producer TPS 直线下降。

指定消费者拦截器具体的实现类要实现 org.apache.kafka.clients.consumer.ConsumerInterceptor 接口，这里面也有两个核心方法。

1. onConsume：该方法在消息返回给 Consumer 程序之前调用。在开始正式处理消息之前，拦截器会先拦一道，搞一些事情，之后再返回。
2. onCommit：Consumer 在提交位移之后调用该方法。通常可以在该方法中做一些记账类的动作，比如打日志等。

注：指定拦截器类时要指定它们的全限定名，即 full qualified name。要把完整包名也加上，不要只有一个类名在那里，并且还要保证 Producer 程序能够正确加载拦截器类。

## 典型使用场景
Kafka 拦截器可以应用于包括客户端监控、端到端系统性能检测、消息审计等多种功能在内的场景。

### 端到端系统性能检测
Kafka 默认提供的监控指标都是针对单个客户端或 Broker 的，很难从具体的消息维度去追踪集群间消息的流转路径。同时，如何监控一条消息从生产到最后消费的端到端延时也是迫切需要解决的问题。

从技术上来说，在客户端程序中增加统计逻辑，但是对于那些将 Kafka 作为企业级基础架构的公司，在应用代码中编写统一的监控逻辑其实是很难的，毕竟这东西非常灵活，不太可能提前确定好所有的计算逻辑。另外，将监控逻辑与主业务逻辑耦合也是软件工程中不提倡的做法。 

通过实现拦截器的逻辑以及可插拔的机制，能够快速地观测、验证以及监控集群间的客户端性能指标，特别是能够从具体的消息层面上去收集这些数据。这就是 Kafka 拦截器的一个非常典型的使用场景。

### 消息审计（message audit）
设想公司把 Kafka 作为一个私有云消息引擎平台向全公司提供服务，这必然要涉及多租户以及消息审计的功能。

作为私有云的 PaaS 提供方，肯定要能够随时查看每条消息是哪个业务方在什么时间发布的，之后又被哪些业务方在什么时刻消费。一个可行的做法就是编写一个拦截器类，实现相应的消息审计逻辑，然后强行规定所有接入 Kafka 服务的客户端程序必须设置该拦截器。

# Java生产者管理TCP连接
## 为何采用 TCP ？
Apache Kafka 的所有通信都是基于 TCP 的，而不是基于 HTTP 或其他协议。无论是生产者、消费者，还是 Broker 之间的通信都是如此。

从社区的角度来看，在开发客户端时，能够利用 TCP本身提供的一些高级功能，比如多路复用请求以及同时轮询多个连接的能力。

社区还发现，目前已知的 HTTP 库在很多编程语言中都略显简陋。

## Kafka 生产者程序概览
Kafka 的 Java 生产者 API 主要的对象就是 KafkaProducer。通常开发一个生产者的步骤有 4 步。
1. 构造生产者对象所需的参数对象。
2. 利用第 1 步的参数对象，创建 KafkaProducer 对象实例。
3. 使用 KafkaProducer 的 send 方法发送消息。
4. 调用 KafkaProducer 的 close 方法关闭生产者并释放各种系统资源。

## 何时创建 TCP 连接？
在创建 KafkaProducer 实例时，生产者应用会在后台创建并启动一个名为 Sender 的线程，该 Sender 线程开始运行时首先会创建与 Broker 的连接。

Producer 启动时会首先创建与这 n 个 Broker 的 TCP 连接。在实际使用过程中，不建议把集群中所有的 Broker 信息都配置到 bootstrap.servers 中，通常指定 3～4 台就足以了。因为 Producer 一旦连接到集群中的任一台 Broker，就能拿到整个集群的 Broker 信息，故没必要为 bootstrap.servers 指定所有的 Broker。

TCP 连接是在创建 KafkaProducer 实例时建立的。TCP 连接还可能在更新元数据后，或者是在消息发送时。当 Producer 更新了集群的元数据信息之后，如果发现与某些 Broker 当前没有连接，那么它就会创建一个 TCP 连接。同样地，当要发送消息时，Producer 发现尚不存在与目标 Broker 的连接，也会创建一个。

Producer 更新集群元数据信息的两个场景：
1. 当 Producer 尝试给一个不存在的主题发送消息时，Broker 会告诉 Producer 说这个主题不存在。此时 Producer 会发送 METADATA 请求给 Kafka 集群，去尝试获取最新的元数据信息。
2. Producer 通过 metadata.max.age.ms 参数定期地去更新元数据信息。该参数的默认值是 300000（5 分钟），即不管集群那边是否有变化，Producer 每 5 分钟都会强制刷新一次元数据以保证它是最及时的数据。

## 何时关闭 TCP 连接？
### 用户主动关闭
* 用户调用 kill -9 主动“杀掉”Producer 应用。
* 最推荐的方式还是调用 producer.close() 方法来关闭。

### Kafka 自动关闭
与 Producer 端参数 connections.max.idle.ms 的值有关。默认情况下该参数值是 9 分钟，即如果在 9 分钟内没有任何请求“流过”某个TCP 连接，那么 Kafka 会主动把该 TCP 连接关闭。用户可以在 Producer 端设置 connections.max.idle.ms=-1 禁掉这种机制。一旦被设置成 -1，TCP 连接将成为永久长连接。这只是软件层面的“长连接”机制，由于 Kafka创建的这些 Socket 连接都开启了 keepalive，因此 keepalive 探活机制还是会遵守的。

注：TCP 连接是在 Broker 端被关闭的，但其实这个 TCP 连接的发起方是客户端，因此在 TCP 看来，这属于被动关闭的场景，即 passive close。被动关闭的后果就是会产生大量的 CLOSE_WAIT 连接，因此 Producer 端或 Client 端没有机会显式地观测到此连接已被中断。

## 小结
1. KafkaProducer 实例创建时启动 Sender 线程，从而创建与 bootstrap.servers 中所有 Broker 的 TCP 连接。
2. KafkaProducer 实例首次更新元数据信息之后，还会再次创建与集群中所有 Broker 的 TCP 连接。
3. 如果 Producer 端发送消息到某台 Broker 时发现没有与该 Broker 的 TCP 连接，那么也会立即创建连接。
4. 如果设置 Producer 端 connections.max.idle.ms 参数大于 0，则步骤 1 中创建的 TCP 连接会被自动关闭；如果设置该参数 =-1，那么步骤 1 中创建的 TCP 连接将无法被关闭，从而成为“僵尸”连接。
